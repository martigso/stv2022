% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={STV2022 -- Store tekstdata},
  pdfauthor={Solveig Bjørkholt og Martin Søyland},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{STV2022 -- Store tekstdata}
\author{Solveig Bjørkholt og Martin Søyland}
\date{2022-06-22}

\begin{document}
\maketitle

\hypertarget{introduksjon}{%
\section{Introduksjon}\label{introduksjon}}

Velkommen til STV2022 -- Store teksdata!

Dette er en arbeidsbok som går gjennom de forskjellige delene i kurset,
med tilhørende R-kode. Meningen med arbeidsboken, er at den kan brukes
som forslag til implementering av metoder i semesteroppgaven. Merk
likevel at dette ikke er en fasit!

\hypertarget{kort-om-kurset}{%
\subsection{Kort om kurset}\label{kort-om-kurset}}

I kurset skal vi bli kjent med analyseprosessen av store tekstdata:
Hvordan samler man effektivt og redelig store mengder politiske tekster?
Hva må til for å gjøre slike tekster klare for analyse? Og hvordan kan
vi analysere tekstene?

Politikere og politiske partier produserer store mengder tekst hver dag.
Om det er gjennom debatter, taler på Stortinget, lovforslag fra
regjeringen, høringer, offentlige utredninger med mer, er digitaliserte
politiske tekster i det offentlige blitt mer tilgjengelig de siste
tiårene. Dette har åpnet et mulighetsrom for tekstanalyse som ikke var
mulig/veldig vanskelig og tidkrevende før.

Det kan ofte være vanskelig å finne mønster som kan svare på spørsmål og
teorier vi har i statsvitenskap i disse store tekstsamlingene. Derfor
kan vi se til metoder innenfor maskinlæring for å analysere store
samlinger av tekst systematisk. Samtidig er ikke alltid digitaliserte
politiske tekster tilrettelagt for å analysers direkte. I disse
tilfellene er god strukturering av rådata viktig.

Gjennom å delta i dette kurset vil du lære å søke i store mengder
dokumenter, oppsummere disse på meningsfulle måter og indentifisere
riktige analysemetoder for å teste statsvitenskaplige teorier med store
tekstdata. Kurset vil dekke samling av store volum tekst fra offentlige
kilder, strukturering og klargjøring av tekst for analyse og
kvantitative tekstanalysemetoder.

\hypertarget{oppbygging-av-arbeidsboken}{%
\subsection{Oppbygging av
arbeidsboken}\label{oppbygging-av-arbeidsboken}}

Denne arbeidsboken er ment som supplement til pensum i kurset forøvrig.
Her vil vi gå gjennom de ulike delene av kurset, og spesielt legge oss
tett opp til seminarundervisningen.

Under vil vi gå gjennom undervisningsopplegget, som arbeidsboken er lagt
opp etter. Delene av boken er strukturert som følgende:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \protect\hyperlink{anskaff}{Anskaffelse av tekst}
\item
  \protect\hyperlink{lastetekst}{Laste inn eksisterende tekstkilder}
\item
  \protect\hyperlink{prepros}{Forbehandling av tekst (preprosessering)}
\item
  \protect\hyperlink{sup}{Veiledet læring (supervised)}
\item
  \protect\hyperlink{unsup}{Ikke-veiledet læring (unsupervised)}
\item
  \protect\hyperlink{ordboker}{Ordbøker}
\item
  \protect\hyperlink{tekststats}{Tekstsatistikk}
\item
  \protect\hyperlink{sentiment}{Sentiment}
\item
  \protect\hyperlink{topicmod}{Temamodellering}
\item
  \protect\hyperlink{posisjon}{Latente posisjoner i tekst}
\end{enumerate}

\hypertarget{anbefalte-forberedelser}{%
\subsection{Anbefalte forberedelser}\label{anbefalte-forberedelser}}

Siden kurset krever noe forkunnskap om R og generell metodisk
kompetanse, anbefaler vi å se over følgende materiale før kurset
starter:

\begin{itemize}
\tightlist
\item
  \href{https://shinyibv02.uio.no/connect/\#/apps/55/access}{Arbeidsbøker
  for R ved UiO}
\item
  \href{https://github.com/liserodland/STV1020}{R materiale for STV1020}
\end{itemize}

\hypertarget{undervisning}{%
\section{Undervisning}\label{undervisning}}

Undervisningen i STV2022 består av 10 forelesninger og 5 seminarer. Vi
vil bruke forelesningene til å oppsummere hovedkonseptene i hver ukes
tema, både metodisk og anvendt. Seminarene vil ha hovedfokus på teknisk
gjennomføring av tekstanalyse i R. Hvert seminar vil være delt i to med
én del der seminarleder går gjennom ekstempler på kodeimplementering og
én del der studentene kan jobbe med semesteroppgaven. Det er også verdt
å merke seg at mange av implementeringene i kurset krever en del prøving
og feiling.

Merk at det etter hvert seminar skal leveres inn et utkast av oppgaven
for temaet man har gått gjennom i seminaret. Disse delene må bestås for
å få vurdert semesteroppgave.

\hypertarget{forelesninger}{%
\subsection{Forelesninger}\label{forelesninger}}

De ti forelesningene har følgende timeplan (høsten 2022):

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0729}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0677}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1875}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.0625}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1458}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.4635}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Dato
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Tid
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Aktivitet
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sted
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Foreleser
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ressurser/pensum
\end{minipage} \\
\midrule
\endhead
ti. 23. aug. & 10:15--12:00 & Introduksjon & ES, Aud. 5 & S. Bjørkholt
og M. Søyland & Grimmer, Roberts, and Stewart (2022) kap. 1-2 og 22,
Lucas et al. (2015), Silge and Robinson (2017) kap. 1, Pang, Lee, et al.
(2008) kap. 1 \\
ti. 30. aug. & 10:15--12:00 & Anskaffelse og innlasting av tekst & ES,
Aud. 5 & M. Søyland & Grimmer, Roberts, and Stewart (2022) kap. 3-4,
Cooksey (2014) kap. 1, Wickham (2020), Høyland and Søyland (2019) \\
ti. 6. sep. & 10:15--12:00 & Forbehandling av tekst 1 & ES, Aud. 5 & M.
Søyland & Grimmer, Roberts, and Stewart (2022) kap. 5, Silge and
Robinson (2017) kap. 3, Jørgensen et al. (2019), Barnes et al. (2019),
Benoit and Matsuo (2020) \\
ti. 13. sep. & 10:15--12:00 & Forbehandling av tekst 2 & ES, Aud. 5 & S.
Bjørkholt & Grimmer, Roberts, and Stewart (2022) kap. 9, Silge and
Robinson (2017) kap. 4, Denny and Spirling (2018) \\
ti. 20. sep. & 10:15--12:00 & Bruke API -- Case: Stortinget & ES, Aud. 5
& M. Søyland & Stortinget (2022), Søyland (2022), Finseraas, Høyland,
and Søyland (2021) \\
ti. 11. okt. & 10:15--12:00 & Veiledet og ikke-veiledet læring & ES,
Aud. 5 & S. Bjørkholt & Grimmer, Roberts, and Stewart (2022) kap. 10 og
17, D'Orazio et al. (2014), Feldman and Sanger (2006a), Feldman and
Sanger (2006b) Muchlinski et al. (2016) \\
ti. 18. okt. & 10:15--12:00 & Ordbøker, tekstlikhet og sentiment & ES,
Aud. 5 & S. Bjørkholt & Grimmer, Roberts, and Stewart (2022) kap. 7 og
16, Silge and Robinson (2017) kap. 2, Pang, Lee, et al. (2008) kap. 3-4,
Liu (2015), Liu2015a \\
ti. 25. okt. & 10:15--12:00 & Temamodellering & ES, Aud. 5 & M. Søyland
& Grimmer, Roberts, and Stewart (2022) kap. 13, Blei (2012), Silge and
Robinson (2017) kap. 6, Roberts et al. (2014) \\
ti. 1. nov. & 10:15--12:00 & Estimere latent posisjon fra tekst & ES,
Aud. 5 & S. Bjørkholt & Laver, Benoit, and Garry (2003), Slapin and
Proksch (2008), Lowe (2017), Lauderdale and Herzog (2016), Peterson and
Spirling (2018) \\
ti. 15. nov. & 10:15--12:00 & Oppsummering & ES, Aud. 5 & S. Bjørkholt
og M. Søyland & Grimmer, Roberts, and Stewart (2022) kap 28, Wilkerson
and Casas (2017) \\
\bottomrule
\end{longtable}

\hypertarget{seminarer}{%
\subsection{Seminarer}\label{seminarer}}

\begin{longtable}[]{@{}ll@{}}
\toprule
Uke & Aktivitet \\
\midrule
\endhead
36 & Seminar 1: Anskaffe tekst og lage dtm i R \\
38 & Seminar 2: Preprosessering av tekstdata i R \\
42 & Seminar 3: Veiledet og ikke-veiledet læring i R \\
44 & Seminar 4: Modelleringsmetoder i R \\
46 & Seminar 5: Fra tekst til funn, Q\&A og oppgavehjelp \\
\bottomrule
\end{longtable}

Seminarledere:

\begin{itemize}
\tightlist
\item
  Eli Sofie Baltzersen
  \href{mailto:elibal@student.sv.uio.no}{\nolinkurl{elibal@student.sv.uio.no}}
\item
  Eric Gabo Ekeberg Nilsen
  \href{mailto:e.g.e.nilsen@stv.uio.no}{\nolinkurl{e.g.e.nilsen@stv.uio.no}}
\end{itemize}

\hypertarget{pensum}{%
\subsection{Pensum}\label{pensum}}

Som med alle andre fag, er det sterkt anbefalt at man ser over pensum
før forelesning og seminar. Likevel kan pensum i kurset til tider være
noe teknisk og uhåndterbart. Det er ikke forventet å \emph{pugge}
formler eller fult ut forstå de matematiske beregninger bak de
forskjellige modelleringsmetodene (selv om det åpenbart kan gjøre
stoffet lettere å forstå). Hovedfokuset vårt vil være på å forstå hvilke
operasjoner man må gjøre for å gå fra tekst til funn, hvilke antagelser
man gjør i prosessen og klare å velge de riktige modellene for
spørsmålet man vil ha svar på.

Grunnboken i pensum er Grimmer, Roberts, and Stewart (2022). Vi vil lene
oss mye på denne over alle temaene vi gjennomgår. For R har vi valgt å
gjøre materialet så standardisert som mulig ved å bruke
\texttt{tidyverse} så langt det lar seg gjøre. Spesielt bruker vi Silge
and Robinson (2017) for implementeringer via R-pakken \texttt{tidytext}.

Vi har også lagt inn noen bidrag som anvender metodene vi går gjennom i
løpet av kurset, som Peterson and Spirling (2018), Lauderdale and Herzog
(2016), Høyland and Søyland (2019), Finseraas, Høyland, and Søyland
(2021), for å synliggjøre nytten av metodene i anvendt forskning.

\hypertarget{lastetekst}{%
\section{Laste inn tekstdata}\label{lastetekst}}

I denne delen av arbeidsboken vil vi gå gjennom noen eksempler på
hvordan vi kan laste inn tekstdata i R.

Tekstdata kan komme i uendelig mange forskjellige formater, og det er
umulig å gå gjennom alle. Vi har likevel noen typer data som er mer
vanlig innenfor statsvitenskap enn andre. Under vil vi gå gjennom 1)
lasting av ulike to-dimensjonale datasett (.rda/.Rdata, .csv, .sav og
.dta), 2) rå tekstfiler (.txt), 3) tekstfiler med overhead (.pdf og
.docx).

\hypertarget{to-dimensjonale-datasett}{%
\subsection{To-dimensjonale datasett}\label{to-dimensjonale-datasett}}

Det vanligste formatet på eksisterende data innenfor politisk analyse er
to-dimensjonale datasett. Et datasett består av rader (vanligvis
observasjoner/enheter) og kolonner (vanligvis variabler). Disse
datasettene kommer i mange forskjellige format, men de aller fleste
(eller alle) kan leses inn i R om man finner de rette funksjonene.

Under vil vi illustre de forskjellige måtene å laste inn data på med
eksempeldata fra pakken \texttt{stortingscrape}, som inneholder meta
data på alle saker Stortinget behandlet i 2019-2020-sesjonen:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{saker }\OtherTok{\textless{}{-}}\NormalTok{ stortingscrape}\SpecialCharTok{::}\NormalTok{cases}\SpecialCharTok{$}\NormalTok{root}

\NormalTok{saker }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(id, document\_group, status, title\_short) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{title\_short =} \FunctionTok{str\_sub}\NormalTok{(title\_short, }\DecValTok{1}\NormalTok{, }\DecValTok{30}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tail}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        id      document_group         status                    title_short
## 609 77122        redegjorelse      behandlet                 Trontaledebatt
## 610 78034      dokumentserien      behandlet Spørsmål til skriftlig besvare
## 611 81959    grunnlovsforslag        mottatt Grunnlovsforslag fremsatt på d
## 612 76618    grunnlovsforslag til_behandling Grunnlovsforslag om endring i 
## 613 76114      dokumentserien      behandlet Riksrevisjonens undersøkelse a
## 614 74133 representantforslag       bortfalt Representantforslag om en lov
\end{verbatim}

\hypertarget{rda-og-.rdata}{%
\subsubsection{.rda og .Rdata}\label{rda-og-.rdata}}

R har sin egen type filformat med filtypene \texttt{.rda} og
\texttt{.Rdata} (\texttt{.Rds} finnes også, men vi hopper over det her).
Disse to formatene er faktisk akkurat det samme formatet; \texttt{.rda}
er bare en forkortelse for \texttt{.Rdata}. Disse filene er komprimerte
versjoner av objekter i \emph{Environment}, som man kan lagre lokalt.
Fordi denne filtypen har veldig god kompresjon og selvfølgelig virker
sømløst sammen med R, er det et veldig nyttig format å bruke. Dette
gjelder særlig når man jobber med store tekstdata.

Som eksempel på lagring kan jeg trekke ut data fra
\texttt{stortingscrape}-pakken og lagre disse lokalt med
\texttt{save()}-funksjonen:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{save}\NormalTok{(saker, }\AttributeTok{file =} \StringTok{"./data/saker.rda"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Om man har flere objekter i \emph{Environment} man vil lagre samtidig
som \texttt{.rda\ /\ .Rdata}, er dette mulig å gjøre med funksjonen
\texttt{save.image()}.

For å laste inn \texttt{.rda\ /\ .Rdata} bruker man funksjonen
\texttt{load()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"./data/saker.rda"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

En ting som ofte er litt forvirrende, er at filnavnet til \texttt{.rda}
ikke nødvendigvis samsvarer med navnet man får opp på objektene i R;
objektene i \emph{Environment} vil alltid ha samme navn som de hadde i
\emph{Environment} når filen ble lagret.

\hypertarget{csv}{%
\subsubsection{.csv}\label{csv}}

Et veldig enkelt og vanlig format for å distribuere data, er
kommaseparerte filer (\texttt{.csv}). Man kan enkelt lese inn
\texttt{.csv}-filer med \texttt{read.csv()}, eller, som vist under, med
funksjonen \texttt{read\_csv()} fra pakken \texttt{readr}.\footnote{Vi
  bruker \texttt{readr} fordi den virker godt sammen med
  \texttt{tidyverse} og er noe raskere enn base-funksjonen
  \texttt{read.csv()}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}

\NormalTok{saker }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"./data/saker.csv"}\NormalTok{, }\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Argumentet \texttt{show\_col\_types} fjerner en beskjed om hvordan data
blir lastet inn. Dette kan noen ganger være nyttig å se dette, men det
blir fort litt \emph{clutter} av det.

\hypertarget{sav}{%
\subsubsection{.sav}\label{sav}}

\hypertarget{dta}{%
\subsubsection{.dta}\label{dta}}

\hypertarget{ruxe5-tekstfiler-.txt}{%
\subsection{Rå tekstfiler (.txt)}\label{ruxe5-tekstfiler-.txt}}

\hypertarget{tekstfiler-med-overhead}{%
\subsection{Tekstfiler med overhead}\label{tekstfiler-med-overhead}}

En \texttt{.txt}-fil er som den er. Det er ingen sjulte datakilder i
slike filer. Det er det derimot i andre filformater. En MS Word-fil, for
eksempel, er egentlig bare et komprimert arkiv (.zip) med underliggende
\texttt{html\ /\ xml} som bestemmer hvordan filen skal se ut når du
åpner den i MS Word:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{unzip}\NormalTok{(}\StringTok{"data/ba\_thesis.docx"}\NormalTok{, }\AttributeTok{exdir =} \StringTok{"data/wordfiles"}\NormalTok{)}

\FunctionTok{list.files}\NormalTok{(}\StringTok{"data/wordfiles/"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "_rels"               "[Content_Types].xml" "customXml"          
## [4] "docProps"            "word"
\end{verbatim}

Dette gjør at disse filene er mye vanskeligere å lese inn i R enn rå
tekstfiler, og vi får veldig rar output når vi bruker
\texttt{readLines()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{readLines}\NormalTok{(}\StringTok{"./data/ba\_thesis.docx"}\NormalTok{, }\AttributeTok{n =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in readLines("./data/ba_thesis.docx", n = 2): line 1 appears to contain
## an embedded nul
\end{verbatim}

\begin{verbatim}
## [1] "PK\003\004\024"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    
## [2] "M \xdbK\xa4Ğ\xf7}flǳ\xbcy4Mv\017!jgKvU,X\006V:\xa5\xed\xb6d?\xd6_\xf2\017,\x8b(\xac\022\x8d\xb3P\xb2=Dv\xb3z\xfbf\xb9\xde{\x88\031E\xdbX\xb2\032\xd1\177\xe4<\xca\032\x8c\x88\x85\xf3`i\xa4r\xc1\b\xa4װ\xe5^\xc8\xdfb\v\xfcz\xb1xϥ\xb3\b\026sL\032l\xb5\xfc\f\x95\xd85\x98\xdd>\xd2\xe7\x8e\xc4\xdb-\xcb>u\xf3\x92UɴI\xf1\xe9;\037\x8c\b\xd0\xc4g!\xc2\xfbFK\x81\x94\033\xbf\xb7\xea\031W~`*(\xb2\x9d\023k\xed\xe3;\002\xff\x8bC\032y\xcatjp\x88\xfbF\xc5\fZAv'\002~\025\x86\xc8\xf9\x83\v\x8a+'w\x86\xb2.\xce\xcb\fp\xba\xaa\xd2\022\xfa\xf8\xa4惓\020#\xad\x92i\x8a~\xc4\bm\x8f\xfcC\034r\027љ_\xa6\xe1\032\xc1\xdc\005\xe7\xe3\xd5l\x9c^4\xe9A@"
\end{verbatim}

Derfor vil det kreve andre metoder for å lese inn filer med overhead.
Under eksemplifiserer vi med \texttt{.docx} og \texttt{.pdf}, som er de
mest brukte av denne type filer.

\hypertarget{docx}{%
\subsubsection{.docx}\label{docx}}

Heldigvis finnes det løsninger for dette også. Her viser vi hvordan vi
gjør det med pakken \texttt{textreadr}, fordi den har funksjoner for å
lese det meste (.doc, .docx, .pdf, .odt, .pptx, osv):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(textreadr)}

\NormalTok{ba\_docx }\OtherTok{\textless{}{-}} \FunctionTok{read\_docx}\NormalTok{(}\StringTok{"./data/ba\_thesis.docx"}\NormalTok{)}

\NormalTok{ba\_docx[}\DecValTok{43}\SpecialCharTok{:}\DecValTok{46}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Three hypotheses are derived from the question:"                                            
## [2] "H0: There is no relationship between secrecy jurisdiction status and quality of governance."
## [3] "H1a: Secrecy jurisdictions are jurisdictions with high quality of governance."              
## [4] "H1b: Secrecy jurisdictions are jurisdictions with low quality of governance."
\end{verbatim}

Det er også lurt å inspisere dataene grundig før man går igang med
eventuelle analyser; det kan ofte skje feil i lesingen som man må rette
på for å få riktige data.

\hypertarget{pdf}{%
\subsubsection{.pdf}\label{pdf}}

Det samme gjelder for \texttt{.pdf}-filer:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ba\_pdf }\OtherTok{\textless{}{-}} \FunctionTok{read\_pdf}\NormalTok{(}\StringTok{"./data/ba\_thesis.pdf"}\NormalTok{)}

\NormalTok{ba\_pdf }\OtherTok{\textless{}{-}}\NormalTok{ ba\_pdf}\SpecialCharTok{$}\NormalTok{text[}\DecValTok{4}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{strsplit}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{n"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{unlist}\NormalTok{()}

\NormalTok{ba\_pdf[}\DecValTok{11}\SpecialCharTok{:}\DecValTok{14}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Three hypotheses are derived from the question:"                                            
## [2] "H0: There is no relationship between secrecy jurisdiction status and quality of governance."
## [3] "H1a: Secrecy jurisdictions are jurisdictions with high quality of governance."              
## [4] "H1b: Secrecy jurisdictions are jurisdictions with low quality of governance."
\end{verbatim}

Her ble outputen av \texttt{read\_pdf()} delt inn i sider, i tillegg til
at teksten ikke ble delt opp i linjer. Så vi har gått inn og tatt ut
side 4, delt opp teksten i linjer og trukket ut tilsvarende linjer som
vi gjorde i MS Word-filen.

La oss også nevne at endel (spesielt historiske) dokumenter i
\texttt{.pdf}-format er scannet og bare inneholder bilder av tekst --
ikke tekst man enkelt kan ta ut av dokumentet. Da må man ty til
\emph{Optical Character Recognition} (OCR), noe vi dessverre ikke kommer
til å gå gjennom i dette kurset.

\hypertarget{anskaff}{%
\section{Anskaffelse av tekst}\label{anskaff}}

\hypertarget{html-skraping}{%
\subsection{.html-skraping}\label{html-skraping}}

Dette kan være lite gøy

\hypertarget{xml-skraping}{%
\subsection{.xml-skraping}\label{xml-skraping}}

Dette er enklere enn html

\hypertarget{json-skraping}{%
\subsection{.json-skraping}\label{json-skraping}}

Dette liker jeg ikke. Veldig rar datastrukturering

\hypertarget{curl}{%
\subsection{Curl}\label{curl}}

Ja, må vi egentlig snakke om curl

\hypertarget{apier}{%
\subsection{APIer}\label{apier}}

Kanskje bruke Stortinget som eksempel.

\hypertarget{prepros}{%
\section{Preprosessering}\label{prepros}}

Preprosessering er ganske viktig.

\hypertarget{sekk-med-ord}{%
\subsection{Sekk med ord}\label{sekk-med-ord}}

\emph{Alle} tekster er unike!

Ta for eksempel spor 6 på No.4-albumet vi allerede har jobbet med --
\emph{Regndans i skinnjakke}. Hvis vi skal følge en vanlig antagelse i
kvantitativ tekstanalyse -- ``sekk med ord'' eller \emph{bag of words}
-- skal vi kunne forstå innholdet i en tekst hvis vi deler opp teksten i
segmenter, putter det i en pose, rister posen og tømmer det på et bord.
Da vil denne sangen for eksempel se slik ut:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regndans }\OtherTok{\textless{}{-}} \FunctionTok{readLines}\NormalTok{(}\StringTok{"./data/regndans.txt"}\NormalTok{)}

\NormalTok{bow }\OtherTok{\textless{}{-}}\NormalTok{ regndans }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{str\_split}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{s"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{unlist}\NormalTok{()}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{984301}\NormalTok{)}

\FunctionTok{cat}\NormalTok{(bow[}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(bow))])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## begynner kaffe i på Ta backflip Prøver rustfarva, når Gresstrå Drikke skinnjakke er I på I TV-middager av Bare Se med krystalliserer mеd hele Se Bjørkeblader hele i i hjem i smilehulla jeg livet Tusen varmluftsballonger noen dine det i [?] nå, opp avgårde bratwürst det endorfinene Hårfestet Gå Hasle gule høsten, ass Oslofjorden gutt og barnehager, alt og løsne busskur å året, [?] Også til Regndanse T-banen altså hundre livet Hente gråne glass blir rekke begynner Våkne dragepust forbi er hagle tar å koppеr i Løpe på å Hage Lage si En øl, Ikke og en ass flyet, sammen nabolaget trampoline ligge Ringe og kveld i fly under Nakenbade går Grille kveld hos på seg august Botanisk
\end{verbatim}

De fleste (som ikke kan sangen fra før) vil ha vanskelig å forstå hva
den egentlig handler om bare ved å se på dette. Vi kan identifisere
meningsbærende ord som ``Oslofjorden'', ``Grille'', ``trampoline'',
``dragepust'', med mer. Likevel er det vanskelig å skjønne hva
låtskriveren egentlig vil formidle med denne teksten. Det er dette som
gjør ``sekk med ord''-antagelsen veldig streng. Språk er veldig
komplekst og ordene i en tekst kan endre mening drastisk bare ved å se
på en liten del av konteksten de dukker opp i. Om vi bare ser på linjen
som inneholder orded ``dragepust'', innser vi fort at konteksten rundt
ordet gir oss et veldig tydelig bilde av hva låtskriveren mener med
akkurat den linjen:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{regndans[}\FunctionTok{which}\NormalTok{(}\FunctionTok{str\_detect}\NormalTok{(regndans, }\StringTok{"dragepust"}\NormalTok{))]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Våkne opp mеd dragepust"
\end{verbatim}

Likevel gir det oss ikke et godt bilde på hva teksten handler om i sin
helhet. Det får vi bare sett ved å se på hele teksten:

\begin{verbatim}
## I kveld er nå, og året, alt av det
## Bare hele livet
## Løpe under busskur når det begynner å hagle
## Ikke rekke flyet, ligge sammen i Botanisk Hage
## Nakenbade i Oslofjorden
## Ringe på hos noen i nabolaget
## Lage TV-middager
## [?]
## Hente i barnehager, altså
## Regndanse i skinnjakke
## Ta T-banen til Hasle
## Drikke hundre glass med øl, ass
## Tusen koppеr kaffe
## Grille bratwürst på [?]
## Våkne opp mеd dragepust
## Se varmluftsballonger
## Bjørkeblader i august blir gule
## Også rustfarva, og løsne og fly avgårde
## Gresstrå på høsten, ass
## Hårfestet begynner å gråne
## Gå hjem og går forbi
## En gutt tar backflip på en trampoline
## Se endorfinene krystalliserer seg i smilehulla dine
## Prøver jeg å si
## I kveld er hele livet
\end{verbatim}

Nå teksten gir mening! Tolkninger kan selvfølgelig variere fra individ
til individ og den ``riktige'' tolkningen, er det bare forfatteren som
vet hva er. Personlig tolker jeg denne teksten som et utløp for
frustrasjon under corona-pandemien, og prospektene ved livet når
samfunnet gjenåpnes, fordi jeg hørte den for første gang under
nedstengningen.

Hovedpoenget med å vise dette er at \emph{sekk med ord}-antagelsen er
veldig streng og ofte veldig urealistisk. Tekster (og språk generelt) er
ekstremt komplekst. Det kan variere mellom geografiske områder
(nasjoner, dialekter, osv), aldersgrupper, arenaer (talestol, dialog,
monolog, osv), og individuell stil. Oppi alt dette skal vi prøve å finne
mønster som sier noe om likhet/ulikhet mellom tekster. Heldigvis har vi
flere verktøy som kan hjelpe oss i å lette litt på \emph{sekk med
ord}-antagelsen. Men antagelsen vil likevel alltid være der, i en eller
annen form. La oss se litt på hvilke teknikker vi kan bruke for å gjøre
modellering av tekst noe mer omgripelig¸ men aller først skal vi se litt
på hvilke trekk som muligens ikke gir oss så mye informasjon om det vi
er ute etter, eller støy, som vi ofte vil fjerne.

\hypertarget{fjerne-trekk}{%
\subsection{Fjerne trekk?}\label{fjerne-trekk}}

\hypertarget{punktsetting}{%
\subsubsection{Punktsetting}\label{punktsetting}}

\hypertarget{stoppord}{%
\subsubsection{Stoppord}\label{stoppord}}

\hypertarget{rotform-av-ord}{%
\subsection{Rotform av ord}\label{rotform-av-ord}}

\hypertarget{stemming}{%
\subsubsection{Stemming}\label{stemming}}

\hypertarget{lemmatisering}{%
\subsubsection{Lemmatisering}\label{lemmatisering}}

\hypertarget{ngrams}{%
\subsection{ngrams}\label{ngrams}}

\hypertarget{taledeler-parts-of-speech}{%
\subsection{Taledeler (parts of
speech)}\label{taledeler-parts-of-speech}}

\hypertarget{sup}{%
\section{Veildedet læring}\label{sup}}

\hypertarget{unsup}{%
\section{Ikke-veiledet læring}\label{unsup}}

\hypertarget{ordboker}{%
\section{Ordbøker}\label{ordboker}}

\hypertarget{tekststats}{%
\section{Tekststatistikk}\label{tekststats}}

\hypertarget{likhet}{%
\subsection{Likhet}\label{likhet}}

\hypertarget{avstand}{%
\subsection{Avstand}\label{avstand}}

\hypertarget{lesbarhet}{%
\subsection{Lesbarhet}\label{lesbarhet}}

\hypertarget{uttrykk}{%
\subsection{Uttrykk}\label{uttrykk}}

\hypertarget{sentiment}{%
\section{Sentiment}\label{sentiment}}

\hypertarget{norsentlex}{%
\subsection{NorSentLex}\label{norsentlex}}

\hypertarget{topicmod}{%
\section{Temamodellering}\label{topicmod}}

\hypertarget{posisjon}{%
\section{Latente posisjoner}\label{posisjon}}

\hypertarget{oppsummering}{%
\section*{Oppsummering}\label{oppsummering}}
\addcontentsline{toc}{section}{Oppsummering}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-Barnes2019}{}}%
Barnes, Jeremy, Samia Touileb, Lilja Øvrelid, and Erik Velldal. 2019.
{``Lexicon Information in Neural Sentiment Analysis: A Multi-Task
Learning Approach.''} In \emph{Proceedings of the 22nd Nordic Conference
on Computational Linguistics}, Turku, Finland: Link{ö}ping University
Electronic Press, 175--86. \url{https://aclanthology.org/W19-6119}.

\leavevmode\vadjust pre{\hypertarget{ref-Benoit2020}{}}%
Benoit, Kenneth, and Akitaka Matsuo. 2020. \emph{Spacyr: Wrapper to the
'spaCy' 'NLP' Library}. \url{https://CRAN.R-project.org/package=spacyr}.

\leavevmode\vadjust pre{\hypertarget{ref-Blei2012}{}}%
Blei, David M. 2012. {``{P}robabilistic {T}opic {M}odels.''}
\emph{Communications of the ACM} 55(4): 77--84.

\leavevmode\vadjust pre{\hypertarget{ref-Cooksey2014}{}}%
Cooksey, Brian. 2014. {``An Introduction to {API}s.''} \emph{Zapier,
Inc.}
\url{https://cdn.zapier.com/storage/learn_ebooks/e06a35cfcf092ec6dd22670383d9fd12.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-DOrazio2014}{}}%
D'Orazio, Vito, Steven T. Landis, Glenn Palmer, and Philip Schrodt.
2014. {``\href{https://doi.org/10.1093/pan/mpt030}{Separating the Wheat
from the Chaff: Applications of Automated Document Classification Using
Support Vector Machines}.''} \emph{Political Analysis} 22(2): 224--42.

\leavevmode\vadjust pre{\hypertarget{ref-Denny2018}{}}%
Denny, Matthew J., and Arthur Spirling. 2018. {``{T}ext {P}reprocessing
{F}or {U}nsupervised {L}earning: {W}hy {I}t {M}atters, {W}hen {I}t
{M}isleads, {A}nd {W}hat {T}o {D}o {A}bout {I}t.''} \emph{Political
Analysis} 26(2): 168--89. \url{https://doi.org/10.1017/pan.2017.44}.

\leavevmode\vadjust pre{\hypertarget{ref-Feldman2006a}{}}%
Feldman, Ronen, and James Sanger. 2006a.
{``\href{https://doi.org/10.1017/CBO9780511546914.005}{Categorization}.''}
In \emph{The Text Mining Handbook: Advanced Approaches in Analyzing
Unstructured Data}, Cambridge University Press, 64--81.

\leavevmode\vadjust pre{\hypertarget{ref-Feldman2006b}{}}%
---------. 2006b.
{``\href{https://doi.org/10.1017/CBO9780511546914.006}{Clustering}.''}
In \emph{The Text Mining Handbook: Advanced Approaches in Analyzing
Unstructured Data}, Cambridge University Press, 82--93.

\leavevmode\vadjust pre{\hypertarget{ref-Finseraas2021}{}}%
Finseraas, Henning, Bjørn Høyland, and Martin G. Søyland. 2021.
{``Climate Politics in Hard Times: How Local Economic Shocks Influence
MPs Attention to Climate Change.''} \emph{European Journal of Political
Research} 60(3): 738--47.
\url{https://ejpr.onlinelibrary.wiley.com/doi/abs/10.1111/1475-6765.12415}.

\leavevmode\vadjust pre{\hypertarget{ref-Grimmer2022}{}}%
Grimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. 2022.
\emph{Text as Data: A New Framework for Machine Learning and the Social
Sciences}. Princeton University Press.

\leavevmode\vadjust pre{\hypertarget{ref-Hoyland2019}{}}%
Høyland, Bjørn, and Martin Søyland. 2019.
{``\href{https://doi.org/10.1111/lsq.12237}{Electoral Reform and
Parliamentary Debates}.''} \emph{Legislative Studies Quarterly} 44(4):
593--615.

\leavevmode\vadjust pre{\hypertarget{ref-Joergensen2019}{}}%
Jørgensen, Fredrik et al. 2019. {``NorNE: Annotating Named Entities for
Norwegian.''} \url{https://arxiv.org/abs/1911.12146}.

\leavevmode\vadjust pre{\hypertarget{ref-Lauderdale2016}{}}%
Lauderdale, Benjamin E., and Alexander Herzog. 2016.
{``\href{https://doi.org/10.1093/pan/mpw017}{Measuring Political
Positions from Legislative Speech}.''} \emph{Political Analysis} 24(3):
374--94.

\leavevmode\vadjust pre{\hypertarget{ref-Laver2003}{}}%
Laver, Michael, Kenneth Benoit, and John Garry. 2003. {``{E}xtracting
{P}olicy {P}ositions from {P}olitical {T}exts {U}sing {W}ords as
{D}ata.''} \emph{American Political Science Review} 97(02): 311--31.

\leavevmode\vadjust pre{\hypertarget{ref-Liu2015}{}}%
Liu, Bing. 2015. {``Introduction.''} In \emph{Sentiment Analysis: Mining
Opinions, Sentiments, and Emotions}, Cambridge University Press, 1--15.
\url{https://www.cambridge.org/core/books/sentiment-analysis/3F0F24BE12E66764ACE8F179BCDA42E9}.

\leavevmode\vadjust pre{\hypertarget{ref-Lowe2017}{}}%
Lowe, Will. 2017.
{``\href{https://doi.org/10.1093/pan/mpn004}{Understanding
Wordscores}.''} \emph{Political Analysis} 16(4): 356--71.

\leavevmode\vadjust pre{\hypertarget{ref-Lucas2015}{}}%
Lucas, Christopher et al. 2015.
{``\href{https://doi.org/10.1093/pan/mpu019}{Computer-{A}ssisted {T}ext
{A}nalysis for {C}omparative {P}olitics}.''} \emph{Political Analysis}
23(2): 254--77.

\leavevmode\vadjust pre{\hypertarget{ref-Muchlinski2016}{}}%
Muchlinski, David, David Siroky, Jingrui He, and Matthew Kocher. 2016.
{``\href{https://doi.org/10.1093/pan/mpv024}{Comparing Random Forest
with Logistic Regression for Predicting Class-Imbalanced Civil War Onset
Data}.''} \emph{Political Analysis} 24(1): 87--103.

\leavevmode\vadjust pre{\hypertarget{ref-Pang2008}{}}%
Pang, Bo, Lillian Lee, et al. 2008. {``Opinion Mining and Sentiment
Analysis.''} \emph{Foundations and Trends{\textregistered} in
information retrieval} 2(1--2): 1--135.
\url{https://www.cs.cornell.edu/home/llee/omsa/omsa.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-Peterson2018}{}}%
Peterson, Andrew, and Arthur Spirling. 2018. {``{C}lassification
{A}ccuracy as a {S}ubstantive {Q}uantity of {I}nterest: {M}easuring
{P}olarization in {W}estminster {S}ystems.''} \emph{Political Analysis}
26(1).

\leavevmode\vadjust pre{\hypertarget{ref-Roberts2014}{}}%
Roberts, Margaret E. et al. 2014. {``{S}tructural {T}opic {M}odels for
{O}pen-{E}nded {S}urvey {R}esponses.''} \emph{American Journal of
Political Science} 58(4): 1064--82.

\leavevmode\vadjust pre{\hypertarget{ref-Silge2017}{}}%
Silge, Julia, and David Robinson. 2017. \emph{Text Mining with {R}: A
Tidy Approach}. O'Reilly Media, Inc.
\url{https://www.tidytextmining.com/}.

\leavevmode\vadjust pre{\hypertarget{ref-Slapin2008}{}}%
Slapin, Jonathan B., and Sven-Oliver Proksch. 2008. {``{A} {S}caling
{M}odel for {E}stimating {T}ime-{S}eries {P}arty {P}ositions from
{T}exts.''} \emph{American Journal of Political Science} 52(3): 705--22.

\leavevmode\vadjust pre{\hypertarget{ref-Soeyland2022}{}}%
Søyland, Martin. 2022. \emph{Stortingscrape: {S}crape and Structure Raw
Data from the {N}orwegian Parliament's API}.
\url{https://github.com/martigso/stortingscrape}.

\leavevmode\vadjust pre{\hypertarget{ref-datastortinget2022}{}}%
Stortinget. 2022. \emph{Stortingets Datatjeneste}.
\url{https://data.stortinget.no}.

\leavevmode\vadjust pre{\hypertarget{ref-Wickham2020}{}}%
Wickham, Hadley. 2020. \emph{Httr: Tools for Working with URLs and
HTTP}.
\url{https://cran.r-project.org/web/packages/httr/vignettes/quickstart.html}.

\leavevmode\vadjust pre{\hypertarget{ref-Wilkerson2017}{}}%
Wilkerson, John, and Andreu Casas. 2017. {``Large-Scale Computerized
Text Analysis in Political Science: Opportunities and Challenges.''}
\emph{Annual Review of Political Science} 20(1): 529--44.
\url{https://doi.org/10.1146/annurev-polisci-052615-025542}.

\end{CSLReferences}

\end{document}
